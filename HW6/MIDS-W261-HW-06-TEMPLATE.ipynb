{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#-MIDS---w261-Machine-Learning-At-Scale-\" data-toc-modified-id=\"-MIDS---w261-Machine-Learning-At-Scale--1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span> MIDS - w261 Machine Learning At Scale </a></div><div class=\"lev2 toc-item\"><a href=\"#Assignment---HW6\" data-toc-modified-id=\"Assignment---HW6-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Assignment - HW6</a></div><div class=\"lev1 toc-item\"><a href=\"#Instructions\" data-toc-modified-id=\"Instructions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Instructions</a></div><div class=\"lev1 toc-item\"><a href=\"#HW6.0.\" data-toc-modified-id=\"HW6.0.-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>HW6.0.</a></div><div class=\"lev2 toc-item\"><a href=\"#HW6.1--Optimization-theory:\" data-toc-modified-id=\"HW6.1--Optimization-theory:-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>HW6.1  Optimization theory:</a></div><div class=\"lev3 toc-item\"><a href=\"#HW6.1.A\" data-toc-modified-id=\"HW6.1.A-311\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>HW6.1.A</a></div><div class=\"lev3 toc-item\"><a href=\"#HW6.1.B\" data-toc-modified-id=\"HW6.1.B-312\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>HW6.1.B</a></div><div class=\"lev3 toc-item\"><a href=\"#HW6.1.C\" data-toc-modified-id=\"HW6.1.C-313\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>HW6.1.C</a></div><div class=\"lev2 toc-item\"><a href=\"#HW6.2\" data-toc-modified-id=\"HW6.2-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>HW6.2</a></div><div class=\"lev2 toc-item\"><a href=\"#HW6.3-Convex-optimization\" data-toc-modified-id=\"HW6.3-Convex-optimization-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>HW6.3 Convex optimization</a></div><div class=\"lev2 toc-item\"><a href=\"#HW-6.4\" data-toc-modified-id=\"HW-6.4-34\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>HW 6.4</a></div><div class=\"lev2 toc-item\"><a href=\"#HW-6.5\" data-toc-modified-id=\"HW-6.5-35\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>HW 6.5</a></div><div class=\"lev3 toc-item\"><a href=\"#HW6.5.1-(OPTIONAL)\" data-toc-modified-id=\"HW6.5.1-(OPTIONAL)-351\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>HW6.5.1 (OPTIONAL)</a></div><div class=\"lev2 toc-item\"><a href=\"#HW6.6-Clean-up-notebook-for-GMM-via-EM-(OPTIONAL)\" data-toc-modified-id=\"HW6.6-Clean-up-notebook-for-GMM-via-EM-(OPTIONAL)-36\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>HW6.6 Clean up notebook for GMM via EM (OPTIONAL)</a></div><div class=\"lev3 toc-item\"><a href=\"#Submission-Instructions\" data-toc-modified-id=\"Submission-Instructions-361\"><span class=\"toc-item-num\">3.6.1&nbsp;&nbsp;</span>Submission Instructions</a></div><div class=\"lev2 toc-item\"><a href=\"#HW6.7--Implement-Bernoulli-Mixture-Model-via-EM-(OPTIONAL)\" data-toc-modified-id=\"HW6.7--Implement-Bernoulli-Mixture-Model-via-EM-(OPTIONAL)-37\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>HW6.7  Implement Bernoulli Mixture Model via EM (OPTIONAL)</a></div><div class=\"lev2 toc-item\"><a href=\"#HW6.8-(OPTIONAL)-1-Million-songs\" data-toc-modified-id=\"HW6.8-(OPTIONAL)-1-Million-songs-38\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>HW6.8 (OPTIONAL) 1 Million songs</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MIDS - w261 Machine Learning At Scale </h1>\n",
    "__Course Lead:__ Dr James G. Shanahan (__email__ Jimi via  James.Shanahan _AT_ gmail.com)\n",
    "\n",
    "<h2>Assignment - HW6</h2>\n",
    "\n",
    "\n",
    "---\n",
    "__Name:__  *Your Name Goes Here*   \n",
    "__Class:__ MIDS w261 (Section *Your Section Goes Here*, e.g., Fall 2016 Group 1)     \n",
    "__Email:__  *Your UC Berkeley Email Goes Here*@iSchool.Berkeley.edu     \n",
    "__StudentId__  123457    __End of StudentId__     \n",
    "__Week:__   6\n",
    "\n",
    "__NOTE:__ please replace `1234567` with your student id above      \n",
    "__Due Time:__ HW is due the Tuesday of the following week by 8AM (West coast time). \n",
    "\n",
    "# Instructions\n",
    "\n",
    "This homework can be completed locally on your computer \n",
    "\n",
    "Follow the instructions for submissions carefully.\n",
    "\n",
    "Each student has a `HW-<user>` repository for all assignments.   \n",
    "\n",
    "Push the following to your HW github repo into the master branch:\n",
    "* Your local HW6 directory. Your repo file structure should look like this:\n",
    "\n",
    "```\n",
    "HW-<user>\n",
    "    --HW3\n",
    "       |__MIDS-W261-HW-03-<Student_id>.ipynb\n",
    "       |__MIDS-W261-HW-03-<Student_id>.pdf\n",
    "       |__some other hw3 file\n",
    "    --HW4\n",
    "       |__MIDS-W261-HW-04-<Student_id>.ipynb\n",
    "       |__MIDS-W261-HW-04-<Student_id>.pdf\n",
    "       |__some other hw4 file\n",
    "    etc..\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW6.0. \n",
    "- In mathematics, computer science, economics, or management science what is mathematical optimization?     \n",
    "- Give an example of a optimization problem that you have worked with directly or that your organization has worked on.    \n",
    "- Please describe the objective function and the decision variables.    \n",
    "- Was the project successful (deployed in the real world)? Describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END STUDENT SOLUTION HW6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW6.1  Optimization theory: \n",
    "\n",
    "### HW6.1.A\n",
    "- For unconstrained univariate optimization what are the first order  Necessary Conditions for Optimality (FOC)?  \n",
    "- What are the second order optimality conditions (SOC)? \n",
    "- Give a mathematical defintion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW6.1.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END STUDENT SOLUTION HW6.1.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW6.1.B\n",
    "In python, plot the univartiate function \n",
    "$$x^3 -12x^2-6 \\ defined \\ over \\ [-6, 6]$$ \n",
    "\n",
    "Also plot its corresponding first and second derivative functions. Eyeballing these graphs, identify candidate optimal points and then classify them as local minimums or maximums. Highlight and label these points in your graphs. Justify your responses using the FOC and SOC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT PLOTS HW6.1.B\n",
    "\n",
    "# END STUDENT PLOTS HW6.1.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW6.1.C\n",
    "- For unconstrained multi-variate optimization what are the first order  Necessary Conditions for Optimality (FOC)?  \n",
    "- What are the second order optimality conditions (SOC)? \n",
    "- Give a mathematical defintion. \n",
    "- What is the Hessian matrix in this context?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW6.1.C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END STUDENT SOLUTION HW6.1.C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW6.2\n",
    "Taking $x_1=1$ as the first approximation(xt1) of a root of $x^3 + 2x -4 = 0$, use the Newton-Raphson method to calculate the second approximation (denoted as $x_2$) of this root.     \n",
    "(Hint the solution is $x_2=1.2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW6.2\n",
    "\n",
    "# END STUDENT SOLUTION HW6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW6.3 Convex optimization \n",
    "- What makes an optimization problem convex? \n",
    "- What are the first order  Necessary Conditions for Optimality in convex optimization?\n",
    "- What are the second order optimality conditions for convex optimization? \n",
    "- Are both necessary to determine the maximum or minimum of candidate optimal solutions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW6.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END STUDENT SOLUTION HW6.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fill in the BLANKS here:   \n",
    "Convex minimization, a subfield of optimization, studies the problem of minimizing **BLANK** functions over **BLANK** sets. The **BLANK** property can make optimization in some sense \"easier\" than the general case - for example, any local minimum must be a global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 6.4\n",
    "\n",
    "The learning objective function for weighted ordinary least squares (WOLS) (aka weight linear regression) is defined as follows:\n",
    "\n",
    "$$0.5* \\sum_{i=1}^n (weight_i * (W * X_i - y_i)^2)$$\n",
    "\n",
    "Where training set consists of input variables X ( in vector form) and a target variable y, and W is the vector of coefficients for the linear regression model.\n",
    "\n",
    "Derive the gradient for this weighted OLS by hand; showing each step and also explaining each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW6.4\n",
    "\n",
    "# END STUDENT SOLUTION HW6.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 6.5\n",
    "Write a MapReduce job in MRJob to do the training at scale of a weighted OLS model using gradient descent. <br>\n",
    "Generate one million datapoints just like in the following notebook:  http://nbviewer.ipython.org/urls/dl.dropbox.com/s/kritdm3mo1daolj/MrJobLinearRegressionGD.ipynb\n",
    "\n",
    "Weight each example as follows: \n",
    "\n",
    "$$weight(x)= abs(1/x)$$\n",
    "\n",
    "Sample 1% of the data in MapReduce and use the sampled dataset to train a (weighted if available in SciKit-Learn) linear regression model locally using  SciKit-Learn (http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "\n",
    "Plot the resulting weighted linear regression model versus the original model that you used to generate the data. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW6.5\n",
    "# insert cells as needed\n",
    "\n",
    "\n",
    "# END STUDENT SOLUTION HW6.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW6.5.1 (OPTIONAL)\n",
    "Using MRJob and in Python, plot the error surface for the weighted linear regression model using a heatmap and contour plot. \n",
    "Also plot the current model in the original domain space.  (Plot them side by side if possible)\n",
    "Plot the path to convergence (during training) for the weighted linear regression model in plot error space and in the original domain space. Make sure to label your plots with iteration numbers, function, model space versus original domain space, etc.\n",
    "Comment on convergence and on the mean squared error using your weighted OLS algorithm on the weighted dataset versus using the weighted OLS algorithm on the uniformly weighted dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW6.5.1\n",
    "# insert cells as needed\n",
    "\n",
    "\n",
    "# END STUDENT SOLUTION HW6.5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW6.6 Clean up notebook for GMM via EM (OPTIONAL)\n",
    "\n",
    "Using the following notebook as a starting point:\n",
    "\n",
    "http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/0t7985e40fovlkw/EM-GMM-MapReduce%20Design%201.ipynb \n",
    "\n",
    "Improve this notebook as follows:\n",
    "- Add in equations into the notebook (not images of equations) \n",
    "- Number the equations\n",
    "- Make sure the equation notation matches the code and the code and comments refer to the equations numbers\n",
    "- Comment the code\n",
    "- Rename/Reorganize the code to make it more readable\n",
    "- Rerun the examples similar graphics (or possibly better graphics)\n",
    "\n",
    "### Submission Instructions\n",
    "Create a new notebook in your github repo and name it: MIDS-W261-HW-06-GMM-{your student id}.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW6.7  Implement Bernoulli Mixture Model via EM (OPTIONAL)\n",
    "Implement the EM clustering algorithm to determine Bernoulli Mixture Model for discrete data in MRJob.\n",
    "\n",
    "As a unit test use the dataset in the following slides:\n",
    "\n",
    "https://www.dropbox.com/s/maoj9jidxj1xf5l/MIDS-Live-Lecture-06-EM-Bernouilli-MM-Systems-Test.pdf?dl=0\n",
    "\n",
    "Cross-check that you get the same cluster assignments and cluster Bernouilli models as presented in the slides after 25 iterations. Dont forget the smoothing.\n",
    "\n",
    "As a full test: use the same dataset from HW 4.5, the Tweet Dataset. \n",
    "Using this data, you will implement a 1000-dimensional EM-based Bernoulli Mixture Model  algorithm in MrJob on the users\n",
    "by their 1000-dimensional word stripes/vectors using K = 4.  Use the same smoothing as in the unit test.\n",
    "\n",
    "Repeat this experiment using your KMeans MRJob implementation fron HW4.\n",
    "Report the rand index score using the class code as ground truth label for both algorithms and comment on your findings.\n",
    "\n",
    "Here is some more information on the Tweet Dataset.\n",
    "\n",
    "Here you will use a different dataset consisting of word-frequency distributions \n",
    "for 1,000 Twitter users. These Twitter users use language in very different ways,\n",
    "and were classified by hand according to the criteria:\n",
    "\n",
    "0: Human, where only basic human-human communication is observed.\n",
    "\n",
    "1: Cyborg, where language is primarily borrowed from other sources\n",
    "(e.g., jobs listings, classifieds postings, advertisements, etc...).\n",
    "\n",
    "2: Robot, where language is formulaically derived from unrelated sources\n",
    "(e.g., weather/seismology, police/fire event logs, etc...).\n",
    "\n",
    "3: Spammer, where language is replicated to high multiplicity\n",
    "(e.g., celebrity obsessions, personal promotion, etc... )\n",
    "\n",
    "Check out the preprints of  recent research,\n",
    "which spawned this dataset:\n",
    "\n",
    "http://arxiv.org/abs/1505.04342\n",
    "http://arxiv.org/abs/1508.01843\n",
    "\n",
    "The main data lie in the accompanying file:\n",
    "\n",
    "[topUsers_Apr-Jul_2014_1000-words.txt](#https://www.dropbox.com/s/6129k2urvbvobkr/topUsers_Apr-Jul_2014_1000-words.txt?dl=0)\n",
    "\n",
    "and are of the form:\n",
    "\n",
    "USERID,CODE,TOTAL,WORD1_COUNT,WORD2_COUNT,...\n",
    ".\n",
    ".\n",
    "\n",
    "where\n",
    "\n",
    "USERID = unique user identifier\n",
    "CODE = 0/1/2/3 class code\n",
    "TOTAL = sum of the word counts\n",
    "\n",
    "Using this data, you will implement a 1000-dimensional K-means algorithm in MrJob on the users\n",
    "by their 1000-dimensional word stripes/vectors using several \n",
    "centroid initializations and values of K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW6.7\n",
    "# insert cells as needed\n",
    "\n",
    "\n",
    "# END STUDENT SOLUTION HW6.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW6.8 (OPTIONAL) 1 Million songs\n",
    "Predict the year of the song. Ask Jimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "397px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "1080px",
    "left": "0px",
    "right": "1804px",
    "top": "107px",
    "width": "245px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
